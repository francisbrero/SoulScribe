{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU openai langchain_community sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import sentence_transformers\n",
    "from datetime import datetime\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://192.168.4.72:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "embedding_function=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_db = Chroma(persist_directory=\"./chromadb\", embedding_function=embedding_function)\n",
    "\n",
    "# Add text to today's file in the data folder\n",
    "def add_to_file(text):\n",
    "    with open(f\"data/{datetime.now().strftime('%Y-%m-%d')}.txt\", \"a\") as f:\n",
    "        f.write(text + \"\\n\")\n",
    "\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are a mental health chatbot. \n",
    "     You are here to help people with their mental health. You ask questions to help the user understand their feelings and emotions. \n",
    "     You can also provide resources and advice. You are not a therapist, but you can help people find the right resources. \n",
    "     Keep your questions short and simple. Ask open-ended questions to encourage the user to share more about their feelings.\n",
    "     Do not spend too much time on one topic. Move on to another topic if you've already asked 4 questions on the same topic. This helps keep the conversation engaging.\n",
    "     Avoid starting your sentences with a rephrasing of the user's input. Instead, ask questions or provide information that can help the user explore their feelings.\n",
    "     Use your past conversations to better guide the conversation.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello. I'm ready to start our session\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Great! Let's start. How are you feeling today?\"},\n",
    "]\n",
    "\n",
    "\n",
    "while True:\n",
    "    completion = client.chat.completions.create(\n",
    "        # model=\"TheBloke/Llama-2-13B-chat-GGUF\", # this field is currently unused\n",
    "        model=\"lmstudio-community/Meta_Llama-3-8B-Instruct-GGUF\", # this field is currently unused\n",
    "        messages=history,\n",
    "        temperature=0.0,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    \n",
    "    for chunk in completion:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "\n",
    "    history.append(new_message)\n",
    "    add_to_file(\"Assistant: \" + new_message[\"content\"])\n",
    "    \n",
    "    #Uncomment to see chat history\n",
    "    import json\n",
    "    gray_color = \"\\033[90m\"\n",
    "    reset_color = \"\\033[0m\"\n",
    "    print(f\"{gray_color}\\n{'-'*20} History dump {'-'*20}\\n\")\n",
    "    print(json.dumps(history, indent=2))\n",
    "    print(f\"\\n{'-'*55}\\n{reset_color}\")\n",
    "\n",
    "    print()\n",
    "    next_input = input(\"> \")\n",
    "    add_to_file(\"Francis: \" + next_input)\n",
    "    search_results = vector_db.similarity_search(next_input, k=2)\n",
    "    some_context = \"\"\n",
    "    for result in search_results:\n",
    "        some_context += result.page_content + \"\\n\\n\"\n",
    "    history.append({\"role\": \"user\", \"content\": some_context + next_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
